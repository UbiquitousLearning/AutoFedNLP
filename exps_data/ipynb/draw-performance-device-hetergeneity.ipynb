{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from brokenaxes import brokenaxes\n",
    "\n",
    "with open(\"sys\",'r') as f:\n",
    "    sys=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metric(mtcs, file): # 文件中共有多少次eval，以及最后一次eval的metric值\n",
    "    i = 0\n",
    "    metric = '\\'acc\\': '\n",
    "    target_str = metric + '\\d+.?\\d+'\n",
    "    number_str = '\\d+.?\\d+'\n",
    "    for line in open(file,\"r\"):\n",
    "        if metric in line:\n",
    "            word = re.findall(target_str, line)[0]\n",
    "            mtc = re.findall(number_str, word)[0]\n",
    "            \n",
    "            mtcs.append(mtc)\n",
    "            i = i + 1\n",
    "    return i, mtcs \n",
    "\n",
    "def get_eval_metric_st(mtcs, file): # 文件中共有多少次eval，以及最后一次eval的metric值\n",
    "    i = 0\n",
    "    metric = '\\'f1_score\\': '\n",
    "    target_str = metric + '\\d+.?\\d+'\n",
    "    number_str = '\\d+.?\\d+'\n",
    "    for line in open(file,\"r\"):\n",
    "        if metric in line:\n",
    "            # print(line.split()[-1].split('}')[0])\n",
    "            # word = re.findall(target_str, line)[0]\n",
    "            # mtc = re.findall(number_str, word)[0]\n",
    "            mtc = line.split()[-1].split('}')[0]\n",
    "            mtcs.append(mtc)\n",
    "            i = i + 1\n",
    "    return i, mtcs \n",
    "\n",
    "def insert_10(left, right):\n",
    "    l = [left + 1]\n",
    "    for i in range(left, right):\n",
    "        if (i - left -1) % 10 == 0 and i != left + 1:\n",
    "            l.append(i)\n",
    "    l.append(right)\n",
    "    return l\n",
    "\n",
    "def merge_stack(lists):\n",
    "    for i in range(len(lists)):\n",
    "        merged_l = []\n",
    "        l = lists[i]\n",
    "        for a in l:\n",
    "            for b in a:\n",
    "                merged_l.append(b)\n",
    "        lists[i] = merged_l\n",
    "    return lists\n",
    "\n",
    "def cut(x,y,upper_bound_acc):\n",
    "    x = np.array(x) / 3600 # convert second to hour\n",
    "    threshold = 0\n",
    "    delete_y = [t for t in y if t > upper_bound_acc]\n",
    "    if len(delete_y) > 0:\n",
    "        if isinstance(y, list):\n",
    "            threshold = y.index(delete_y[0])\n",
    "        else:\n",
    "            threshold = y.tolist().index(delete_y[0])\n",
    "    else:\n",
    "        threshold = len(y)\n",
    "    y = y[:threshold]\n",
    "    x = x[:threshold]\n",
    "    return x,y\n",
    "            \n",
    "def sum_duration(depth, width, idx, tmp, time, type = \"Dyna-A-Freeze\", slow_down = 1, dataset = \"20news\"):\n",
    "    bw = 1\n",
    "    if dataset == \"20news\":\n",
    "        batch_num = 29\n",
    "    if dataset == \"agnews\":\n",
    "        batch_num = 30\n",
    "    if dataset == \"semeval\":\n",
    "        batch_num = 20\n",
    "    if dataset == \"onto\":\n",
    "        batch_num = 20\n",
    "\n",
    "    if dataset == \"20news\" or dataset == \"onto\":\n",
    "        latency_tx2_baseline = np.array([0.5325, 0.612, 0.696, 0.791, 0.883, 0.9713, 1.064, 1.156, 1.2465, 1.33, 1.419, 1.51, 1.7]) * slow_down\n",
    "        latency_tx2_cached = np.array([0.02, 0.09, 0.18, 0.27, 0.36, 0.45, 0.54, 0.63, 0.72, 0.81, 0.90, 0.99, 1.08]) * slow_down # msl = 256\n",
    "    else:\n",
    "        latency_tx2_baseline = np.array([0.5325, 0.612, 0.696, 0.791, 0.883, 0.9713, 1.064, 1.156, 1.2465, 1.33, 1.419, 1.51, 1.7]) / 4 * slow_down\n",
    "        latency_tx2_cached = np.array([0.02, 0.09, 0.18, 0.27, 0.36, 0.45, 0.54, 0.63, 0.72, 0.81, 0.90, 0.99, 1.08]) / 4 * slow_down# msl = 64\n",
    "    comm_bert = np.array([0.6, 7.7, 14.8, 21.9, 29.0, 36.0, 43.1, 50.2, 57.3, 64.4, 71.5, 78.6, 109.5]) * 32 / 8 / bw # 这里面没有仅仅freeze embedding的数据\n",
    "    adapter_para = 0.0125 * width / 8\n",
    "    comm_adapter =np.array([0.02 + i * adapter_para for i in range(0,13)]) * 4 / bw\n",
    "    \n",
    "    if type == \"BERT\" or type == \"Freeze\":\n",
    "        latency = latency_tx2_baseline\n",
    "        comm = comm_bert * 2\n",
    "    if type == \"Q-Freeze\": # 使用误差补偿的方法; Quantize Freeze; TODO:混合精度量化\n",
    "        latency = latency_tx2_baseline\n",
    "        if depth > 2:\n",
    "            comm = comm_bert * 2 / 4  # INT8 量化 for depth >= 2\n",
    "        else:\n",
    "            comm = comm_bert * 2 / 8  # INT4 量化 for depth < 2\n",
    "    if type == \"Quantize\" : # 使用误差补偿的方法; Quantize Freeze; TODO:混合精度量化\n",
    "        latency = latency_tx2_baseline\n",
    "        comm = comm_bert * 2 / 4  # INT8 量化\n",
    "    if type == \"A-Freeze\" or type == \"Dyna-A-Freeze\":\n",
    "        latency = latency_tx2_cached \n",
    "        comm = comm_adapter * 2\n",
    "\n",
    "    comm_tmp = comm[depth]\n",
    "    duration = 0\n",
    "    for i in range(0, idx - tmp):\n",
    "        comp_tmp = latency[depth] * batch_num\n",
    "        duration = duration + comp_tmp + comm_tmp\n",
    "        # print(comp_tmp,comm_tmp)\n",
    "    if len(time) > 0:\n",
    "        time.append(duration + time[-1])\n",
    "    else:\n",
    "        time.append(duration)\n",
    "    return time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = 60 # font size\n",
    "lw = 5 # line width\n",
    "color = ['blue', 'green', '#FF8C00', '#9370DB', 'red','hotpink']\n",
    "marker = [\"o\", \"v\", \"s\", \"^\", \"D\", \"o\"]\n",
    "target_acc = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tx2': [43.95175, 12.744250000000001, 18.5163622222222, 5.160140000000001, 1.341133333333335], 'nano': [46.2935, 15.086, 21.21316888888888, 8.137280000000002, 2.493722222222222], 'rpi': [88.445, 57.2375, 69.75568888888883, 61.72579999999994, 23.240322222222233]}\n"
     ]
    }
   ],
   "source": [
    "# 无特效\n",
    "# 20news\n",
    "root_path = \"/Users/cdq/Desktop/opensource/FedFinetuning/\"\n",
    "log_root_path = \"data/nice_results/20news-Trail-0-60\"\n",
    "log_file_name = \"fednlp_tc_deep_0.log\"\n",
    "file = os.path.join(root_path, log_root_path, log_file_name)\n",
    "\n",
    "\n",
    "# depth, width, round, metric\n",
    "dwrm = [[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3], [8, 8, 8, 16, 16, 16, 24, 32, 32, 32, 40, 48, 48, 48, 56, 64, 64, 64, 64, 64], [-1, 79, 88, 180, 272, 364, 453, 539, 625, 711, 794, 875, 956, 1037, 1115, 1191, 1267, 1343, 1393, 1467], [0, '0.4681359532660648', '0.602761550716941', '0.7422995220392989', '0.7559745087626129', '0.7636749867233139', '0.7684545937334042', '0.7729686670207117', '0.7804036112586299', '0.7838555496548062', '0.7892989909718534', '0.7934147636749868', '0.7954062665958577', '0.7966011683483802', '0.7980616038236856', '0.8005841741901222', '0.8029739776951673', '0.8016463090812533', '0.8020446096654275', '0.8031067445565587']]\n",
    "\n",
    "\n",
    "flag = [\"init\"]\n",
    "trial_num = len(dwrm[0])\n",
    "for i in range(trial_num-1):\n",
    "    depth = dwrm[0]\n",
    "    width = dwrm[1]\n",
    "    if depth[i+1] > depth[i]: # deeper\n",
    "        flag.append(\"deep\")\n",
    "    elif width[i+1] > width[i]: # wider\n",
    "        flag.append(\"wide\")\n",
    "    else:\n",
    "        flag.append(\"shallow\")\n",
    "dwrm.append(flag)\n",
    "\n",
    "new_dwrm = [[],[],[],[]]\n",
    "for i in range(1, trial_num):\n",
    "    mtcs = [] # metric\n",
    "    log_file_name = \"fednlp_tc_\" + dwrm[-1][i] + \"_\" + str(i-1) + \".log\"\n",
    "    file = os.path.join(root_path, log_root_path, log_file_name)\n",
    "    count, mtcs = get_eval_metric(mtcs, file)\n",
    "    new_dwrm[0].append([dwrm[0][i]] * count)\n",
    "    new_dwrm[1].append([dwrm[1][i]] * count)\n",
    "    new_dwrm[2].append(insert_10(dwrm[2][i-1], dwrm[2][i]))\n",
    "    new_dwrm[3].append(mtcs) # mtcs是对的，其它不知道\n",
    "# print(new_dwrm)\n",
    "\n",
    "merged_new_dwrm = merge_stack(new_dwrm)\n",
    "# print(merged_new_dwrm)\n",
    "# for depth in dwrm:\n",
    "\n",
    "Origin = os.path.join(root_path,\"data/Baseline/20news_uniform_lr=0.1_freeze=_quantize=False_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Quant = os.path.join(root_path,\"data/Baseline/20news_uniform_lr=0.1_freeze=_quantize=True_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Q_Freeze = os.path.join(root_path,\"data/Baseline/20news_uniform_lr=0.1_freeze=e,0,1,2,3,4,5,6,7,8,9_quantize=True_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Freeze = os.path.join(root_path,\"data/Baseline/20news_uniform_lr=0.1_freeze=e,0,1,2,3,4,5,6,7,8,9_quantize=False_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*10).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_origin_drm = load_baseline(12, Origin)\n",
    "baseline_quant = load_baseline(12, Quant)\n",
    "baseline_q_freeze_drm = load_baseline(2, Q_Freeze)\n",
    "baseline_freeze_drm = load_baseline(2, Freeze)\n",
    "\n",
    "\n",
    "\n",
    "max_acc = 0.8\n",
    "max_acc = max_acc * target_acc\n",
    "bws = [1, 2, 20] # actually is slow down\n",
    "\n",
    "runtime = {\n",
    "    \"tx2\": [],\n",
    "    \"nano\": [],\n",
    "    \"rpi\": []\n",
    "}\n",
    "\n",
    "i = 0\n",
    "device = [\"tx2\", \"nano\",\"rpi\"]\n",
    "for bw in bws:\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_origin_drm\n",
    "    y = [float(i) for i in baseline_origin_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"BERT\", bw, \"20news\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"BERT\")\n",
    "    # print(\"BERT\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_origin_drm\n",
    "    y = [float(i) for i in baseline_origin_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Quantize\", bw, \"20news\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Quant\")\n",
    "    # print(\"Quant\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_freeze_drm\n",
    "    y = [float(i) for i in baseline_freeze_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Freeze\", bw, \"20news\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Freeze\")\n",
    "    # print(\"Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_q_freeze_drm\n",
    "    y = [float(i) for i in baseline_q_freeze_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Q-Freeze\", bw, \"20news\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Q-Freeze\")\n",
    "    # print(\"Q-Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    data = new_dwrm\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    y = [float(i) for i in data[3]]\n",
    "    for idx in data[2]:\n",
    "        id = data[2].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = data[1][id]\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Dyna-A-Freeze\", bw, \"20news\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Dyna-A-Freeze\")\n",
    "    # print(\"Dyna-A-Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "    i = i + 1\n",
    "\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tx2': [73.075, 19.055, 17.547172222222205, 3.1753944444444464, 1.0431916666666652], 'nano': [74.12333333333333, 20.10333333333333, 18.28812222222224, 4.003344444444441, 1.6923166666666678], 'rpi': [92.99333333333334, 38.973333333333336, 31.625222222222224, 18.906444444444443, 13.376566666666651]}\n"
     ]
    }
   ],
   "source": [
    "# 无特效\n",
    "# agnews\n",
    "root_path = \"/Users/cdq/Desktop/opensource/FedFinetuning/\"\n",
    "log_root_path = \"data/nice_results/agnews-Trail-0-90\"\n",
    "log_file_name = \"fednlp_tc_deep_0.log\"\n",
    "file = os.path.join(root_path, log_root_path, log_file_name)\n",
    "ft = 60 # font size\n",
    "\n",
    "# depth, width, round, metric\n",
    "dwrm = [[0, 0, 0, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6], [8, 16, 16, 16, 24, 24, 24, 24, 24, 24, 32, 32, 40, 40, 40, 48, 48, 48, 56, 64, 64, 72], [-1, 116, 233, 247, 377, 507, 594, 720, 846, 941, 1061, 1157, 1272, 1387, 1502, 1614, 1726, 1819, 1927, 2032, 2137, 2242], [0, '0.7171052631578947', '0.8127631578947369', '0.8092105263157895', '0.8567105263157895', '0.8693421052631579', '0.8747368421052631', '0.8744736842105263', '0.8794736842105263', '0.8806578947368421', '0.8825', '0.886578947368421', '0.891578947368421', '0.8927631578947368', '0.8956578947368421', '0.8992105263157895', '0.8997368421052632', '0.9021052631578947', '0.9031578947368422', '0.9028947368421053', '0.9032894736842105', '0.906578947368421']]\n",
    "\n",
    "\n",
    "flag = [\"init\"]\n",
    "trial_num = len(dwrm[0])\n",
    "for i in range(trial_num-1):\n",
    "    depth = dwrm[0]\n",
    "    width = dwrm[1]\n",
    "    if depth[i+1] > depth[i]: # deeper\n",
    "        flag.append(\"deep\")\n",
    "    elif width[i+1] > width[i]: # wider\n",
    "        flag.append(\"wide\")\n",
    "    else:\n",
    "        flag.append(\"shallow\")\n",
    "dwrm.append(flag)\n",
    "\n",
    "new_dwrm = [[],[],[],[]]\n",
    "for i in range(1, trial_num):\n",
    "    mtcs = [] # metric\n",
    "    log_file_name = \"fednlp_tc_\" + dwrm[-1][i] + \"_\" + str(i-1) + \".log\"\n",
    "    file = os.path.join(root_path, log_root_path, log_file_name)\n",
    "    count, mtcs = get_eval_metric(mtcs, file)\n",
    "    new_dwrm[0].append([dwrm[0][i]] * count)\n",
    "    new_dwrm[1].append([dwrm[1][i]] * count)\n",
    "    new_dwrm[2].append(insert_10(dwrm[2][i-1], dwrm[2][i]))\n",
    "    new_dwrm[3].append(mtcs) # mtcs是对的，其它不知道\n",
    "# print(new_dwrm)\n",
    "\n",
    "merged_new_dwrm = merge_stack(new_dwrm)\n",
    "# print(merged_new_dwrm)\n",
    "# for depth in dwrm:\n",
    "\n",
    "Origin = os.path.join(root_path,\"data/Baseline/agnews_niid_label_clients=1000_alpha=10.0_lr=0.1_freeze=_quantize=False_adapter=False_length=64.txt\")\n",
    "Quant = os.path.join(root_path,\"data/Baseline/agnews_niid_label_clients=1000_alpha=10.0_lr=0.1_freeze=_quantize=True_adapter=False_length=64.txt\")\n",
    "Q_Freeze = os.path.join(root_path,\"data/Baseline/agnews_niid_label_clients=1000_alpha=10.0_lr=0.1_freeze=e,0,1,2,3,4,5,6,7,8,9_quantize=True_adapter=False_MSL=64_workers15_rounds10.txt\")\n",
    "Freeze = os.path.join(root_path,\"data/Baseline/agnews_niid_label_clients=1000_alpha=10.0_lr=0.1_freeze=e,0,1,2,3,4,5,6,7,8,9_quantize=False_adapter=False_MSL=64_workers15_rounds10.txt\")\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*5).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_origin_drm = load_baseline(12, Origin)\n",
    "baseline_quant = load_baseline(12, Quant)\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*10).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_q_freeze_drm = load_baseline(2, Q_Freeze)\n",
    "baseline_freeze_drm = load_baseline(2, Freeze)\n",
    "# print(baseline_quant)\n",
    "\n",
    "max_acc = 0.9\n",
    "max_acc = max_acc * target_acc\n",
    "bws = [1, 2, 20] # actually is slow down\n",
    "\n",
    "runtime = {\n",
    "    \"tx2\": [],\n",
    "    \"nano\": [],\n",
    "    \"rpi\": []\n",
    "}\n",
    "\n",
    "i = 0 \n",
    "device = [\"tx2\", \"nano\",\"rpi\"]\n",
    "for bw in bws:\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_origin_drm\n",
    "    y = [float(i) for i in baseline_origin_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"BERT\", bw,\"agnews\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"BERT\")\n",
    "    # print(\"BERT\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_origin_drm\n",
    "    y = [float(i) for i in baseline_origin_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Quantize\", bw,\"agnews\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Quant\")\n",
    "    # print(\"Quant\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_freeze_drm\n",
    "    y = [float(i) for i in baseline_freeze_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Freeze\", bw,\"agnews\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Freeze\")\n",
    "    # print(\"Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_q_freeze_drm\n",
    "    y = [float(i) for i in baseline_q_freeze_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Q-Freeze\", bw,\"agnews\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Q-Freeze\")\n",
    "    # print(\"Q-Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    data = new_dwrm\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    y = [float(i) for i in data[3]]\n",
    "    for idx in data[2]:\n",
    "        id = data[2].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = data[1][id]\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Dyna-A-Freeze\", bw,\"agnews\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Dyna-A-Freeze\")\n",
    "    # print(\"Dyna-A-Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "    i = i + 1\n",
    "\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tx2': [124.32138888888889, 31.976388888888888, 74.0114777777779, 16.80408888888887, 2.331736111111116], 'nano': [125.51611111111112, 33.17111111111111, 75.13606666666661, 17.780900000000017, 3.7053611111111224], 'rpi': [147.0211111111111, 54.67611111111111, 95.37866666666667, 35.3635, 28.43061111111116]}\n"
     ]
    }
   ],
   "source": [
    "# semeval v3.0\n",
    "root_path = \"/Users/cdq/Desktop/opensource/FedFinetuning/\"\n",
    "log_root_path = \"data/nice_results/semeval_2010_task8-Trail-1-90\"\n",
    "log_file_name = \"semeval_2010_task8-depth-0-freq-90.log\"\n",
    "file = os.path.join(root_path, log_root_path, log_file_name)\n",
    "ft = 60 # font size\n",
    "\n",
    "# \n",
    "dwrm = [[1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12], [8, 16, 16, 16, 16, 16, 16, 16, 16, 24, 32, 32, 32, 32, 32, 40, 48, 48, 48, 56, 56, 56, 56], [-1, 206, 249, 434, 619, 804, 989, 1174, 1359, 1535, 1703, 1871, 1964, 2088, 2253, 2410, 2561, 2712, 2863, 3008, 3153, 3298, 3443],\n",
    "[0, '0.2528524107471476', '0.3257269046742731', '0.6352594773647405', '0.6838424733161576', '0.7143908722856092', '0.7364740522635259', '0.7534044902465955', '0.7603974972396025', '0.7684946632315053', '0.7762237762237763', '0.7813765182186235', '0.7854251012145749', '0.7894736842105263', '0.7994111152005889', '0.805668016194332', '0.805668016194332', '0.8100846521899153', '0.8100846521899153', '0.8141332351858668', '0.8185498711814502', '0.8181818181818182', '0.819654030180346']]\n",
    "\n",
    "\n",
    "flag = [\"init\"]\n",
    "trial_num = len(dwrm[0])\n",
    "for i in range(trial_num-1):\n",
    "    depth = dwrm[0]\n",
    "    width = dwrm[1]\n",
    "    if depth[i+1] > depth[i]: # deeper\n",
    "        flag.append(\"deep\")\n",
    "    elif width[i+1] > width[i]: # wider\n",
    "        flag.append(\"wide\")\n",
    "    else:\n",
    "        flag.append(\"shallow\")\n",
    "dwrm.append(flag)\n",
    "\n",
    "new_dwrm = [[],[],[],[]]\n",
    "for i in range(1, trial_num):\n",
    "    mtcs = [] # metric\n",
    "    log_file_name = \"fednlp_tc_\" + dwrm[-1][i] + \"_\" + str(i-1) + \".log\"\n",
    "    file = os.path.join(root_path, log_root_path, log_file_name)\n",
    "    count, mtcs = get_eval_metric(mtcs, file)\n",
    "    new_dwrm[0].append([dwrm[0][i]] * count)\n",
    "    new_dwrm[1].append([dwrm[1][i]] * count)\n",
    "    new_dwrm[2].append(insert_10(dwrm[2][i-1], dwrm[2][i]))\n",
    "    new_dwrm[3].append(mtcs) # mtcs是对的，其它不知道\n",
    "# print(new_dwrm)\n",
    "\n",
    "merged_new_dwrm = merge_stack(new_dwrm)\n",
    "# print(merged_new_dwrm)\n",
    "# for depth in dwrm:\n",
    "\n",
    "Origin = os.path.join(root_path,\"data/Baseline/semeval_2010_task8_niid_label_clients=100_alpha=100_lr=0.1_freeze=_quantize=False_adapter=False_length=64.txt\")\n",
    "Quant = os.path.join(root_path,\"data/Baseline/semeval_2010_task8_niid_label_clients=100_alpha=100_lr=0.1_freeze=_quantize=True_adapter=False_length=64.txt\")\n",
    "Q_Freeze = os.path.join(root_path,\"data/Baseline/semeval_2010_task8_niid_label_clients=100_alpha=100_lr=0.1_freeze=e,0,1,2,3,4,5_quantize=True_adapter=False_MSL=64_workers15_rounds10.txt\")\n",
    "Freeze = os.path.join(root_path,\"data/Baseline/semeval_2010_task8_niid_label_clients=100_alpha=100_lr=0.1_freeze=e,0,1,2,3,4,5_quantize=False_adapter=False_MSL=64_workers15_rounds10.txt\")\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*5).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_origin_drm = load_baseline(12, Origin)\n",
    "baseline_quant = load_baseline(12, Quant)\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*10).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_q_freeze_drm = load_baseline(6, Q_Freeze)\n",
    "baseline_freeze_drm = load_baseline(6, Freeze)\n",
    "\n",
    "max_acc = 0.8\n",
    "max_acc = max_acc * target_acc\n",
    "bws = [1, 2, 20] # actually is slow down\n",
    "\n",
    "runtime = {\n",
    "    \"tx2\": [],\n",
    "    \"nano\": [],\n",
    "    \"rpi\": []\n",
    "}\n",
    "\n",
    "i = 0\n",
    "device = [\"tx2\", \"nano\",\"rpi\"]\n",
    "for bw in bws:\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_origin_drm\n",
    "    y = [float(i) for i in baseline_origin_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"BERT\", bw, \"semeval\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"BERT\")\n",
    "    # print(\"BERT\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_origin_drm\n",
    "    y = [float(i) for i in baseline_origin_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Quantize\", bw, \"semeval\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Quant\")\n",
    "    # print(\"Quant\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_freeze_drm\n",
    "    y = [float(i) for i in baseline_freeze_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Freeze\", bw, \"semeval\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Freeze\")\n",
    "    # print(\"Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_q_freeze_drm\n",
    "    y = [float(i) for i in baseline_q_freeze_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Q-Freeze\", bw, \"semeval\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Q-Freeze\")\n",
    "    # print(\"Q-Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    data = new_dwrm\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    y = [float(i) for i in data[3]]\n",
    "    for idx in data[2]:\n",
    "        id = data[2].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = data[1][id]\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Dyna-A-Freeze\", bw, \"semeval\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Dyna-A-Freeze\")\n",
    "    # print(\"Dyna-A-Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "    i = i + 1\n",
    "\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tx2': [76.08611111111111, 21.15361111111111, 82.46968888888878, 23.914300000000036, 10.403972222222201], 'nano': [78.92888888888889, 23.996388888888887, 87.2636, 28.649100000000036, 18.269972222222187], 'rpi': [130.0988888888889, 75.16638888888889, 173.554, 113.8755, 159.85797222222186]}\n"
     ]
    }
   ],
   "source": [
    "# onto\n",
    "root_path = \"/Users/cdq/Desktop/opensource/FedFinetuning/\"\n",
    "log_root_path = \"data/nice_results/onto-Trail-1-100\"\n",
    "log_file_name = \"fednlp_tc_deep_0.log\"\n",
    "file = os.path.join(root_path, log_root_path, log_file_name)\n",
    "ft = 60 # font size\n",
    "\n",
    "# \n",
    "dwrm = [[1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 9, 9, 12, 12, 12, 12, 12, 12, 12], [8, 8, 16, 24, 24, 32, 32, 32, 32, 40, 40, 40, 40, 48, 56, 56, 56, 64, 72], [-1, 240, 470, 690, 910, 1120, 1163, 1350, 1537, 1716, 1815, 1991, 2123, 2291, 2452, 2613, 2774, 2929, 3084],\n",
    "[0, '0.5275039583226928', '0.5616751017167807', '0.5828858564461303', '0.591306972532448', '0.6005060728744939', '0.6078450745973718', '0.6285714285714286', '0.6495439025633185', '0.6629558341569994', '0.6721102322020924', '0.6921341239439576', '0.7079159096807683', '0.7206368899917287', '0.731308043444042', '0.7382902751522789', '0.7469370511195607', '0.7527915798471976', '0.7577876668785759']]\n",
    "\n",
    "flag = [\"init\"]\n",
    "trial_num = len(dwrm[0])\n",
    "for i in range(trial_num-1):\n",
    "    depth = dwrm[0]\n",
    "    width = dwrm[1]\n",
    "    if depth[i+1] > depth[i]: # deeper\n",
    "        flag.append(\"deep\")\n",
    "    elif width[i+1] > width[i]: # wider\n",
    "        flag.append(\"wide\")\n",
    "    else:\n",
    "        flag.append(\"shallow\")\n",
    "dwrm.append(flag)\n",
    "\n",
    "new_dwrm = [[],[],[],[]]\n",
    "for i in range(1, trial_num):\n",
    "    mtcs = [] # metric\n",
    "    log_file_name = \"fednlp_tc_\" + dwrm[-1][i] + \"_\" + str(i-1) + \".log\"\n",
    "    file = os.path.join(root_path, log_root_path, log_file_name)\n",
    "    count, mtcs = get_eval_metric_st(mtcs, file)\n",
    "    new_dwrm[0].append([dwrm[0][i]] * count)\n",
    "    new_dwrm[1].append([dwrm[1][i]] * count)\n",
    "    new_dwrm[2].append(insert_10(dwrm[2][i-1], dwrm[2][i]))\n",
    "    new_dwrm[3].append(mtcs) # mtcs是对的，其它不知道\n",
    "# print(new_dwrm)\n",
    "\n",
    "merged_new_dwrm = merge_stack(new_dwrm)\n",
    "# print(merged_new_dwrm)\n",
    "# for depth in dwrm:\n",
    "\n",
    "Origin = os.path.join(root_path,\"data/Baseline/onto_niid_label_clients=30_alpha=1.0_lr=0.1_freeze=_quantize=False_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Quant = os.path.join(root_path,\"data/Baseline/onto_niid_label_clients=30_alpha=1.0_lr=0.1_freeze=_quantize=True_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Q_Freeze = os.path.join(root_path,\"data/Baseline/onto_niid_label_clients=30_alpha=1.0_lr=0.1_freeze=e,0,1,2,3,4,5_quantize=False_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Freeze = os.path.join(root_path,\"data/Baseline/onto_niid_label_clients=30_alpha=1.0_lr=0.1_freeze=e,0,1,2,3,4,5_quantize=True_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*10).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_origin_drm = load_baseline(12, Origin)\n",
    "baseline_quant = load_baseline(12, Quant)\n",
    "# baseline_q_freeze_drm = load_baseline(6, Q_Freeze)\n",
    "# 对应table2，此处应该至少是8\n",
    "baseline_q_freeze_drm = load_baseline(6, Q_Freeze)\n",
    "baseline_freeze_drm = load_baseline(6, Freeze)\n",
    "\n",
    "\n",
    "\n",
    "max_acc = 0.75\n",
    "# target_acc = 0.99\n",
    "max_acc = max_acc * target_acc\n",
    "bws = [1, 2, 20] # actually is slow down\n",
    "\n",
    "runtime = {\n",
    "    \"tx2\": [],\n",
    "    \"nano\": [],\n",
    "    \"rpi\": []\n",
    "}\n",
    "\n",
    "i = 0\n",
    "device = [\"tx2\", \"nano\",\"rpi\"]\n",
    "for bw in bws:\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_origin_drm\n",
    "    y = [float(i) for i in baseline_origin_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"BERT\", bw, \"onto\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"BERT\")\n",
    "    # print(\"BERT\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_quant\n",
    "    y = [float(i) for i in baseline_origin_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Quantize\", bw, \"onto\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Quant\")\n",
    "    # print(\"Quant\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_freeze_drm\n",
    "    y = [float(i) for i in baseline_freeze_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Freeze\", bw, \"onto\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Freeze\")\n",
    "    # print(\"Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    data = baseline_q_freeze_drm\n",
    "    y = [float(i) for i in baseline_q_freeze_drm[2]]\n",
    "    for idx in data[1]:\n",
    "        id = data[1].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = 0\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Q-Freeze\", bw, \"onto\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    # plt.plot(np.array(time), y, label = \"Q-Freeze\")\n",
    "    # print(\"Q-Freeze\",time[-1])\n",
    "    runtime[device[i]].append(time[-1])\n",
    "\n",
    "    time = []\n",
    "    data = new_dwrm\n",
    "    tmp = -1 # 记录最后一个访问的idx\n",
    "    y = [float(i) for i in data[3]]\n",
    "    for idx in data[2]:\n",
    "        id = data[2].index(idx)\n",
    "        d = data[0][id]\n",
    "        w = data[1][id]\n",
    "        time = sum_duration(d, w, idx, tmp, time, \"Dyna-A-Freeze\",bw, \"onto\")\n",
    "        tmp = idx\n",
    "\n",
    "    time, y = cut(time, y, max_acc)\n",
    "    runtime[device[i]].append(time[-1])\n",
    "    i = i + 1\n",
    "\n",
    "print(runtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b70465f8729e5d3096f68a9386b4f93afdddeed84afbab797b784e9c714821a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('fednlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
