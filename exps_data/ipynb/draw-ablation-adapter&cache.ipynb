{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AdaFL'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "\n",
    "with open(\"sys\",'r') as f:\n",
    "    sys=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metric(mtcs, file): # 文件中共有多少次eval，以及最后一次eval的metric值\n",
    "    i = 0\n",
    "    metric = '\\'acc\\': '\n",
    "    target_str = metric + '\\d+.?\\d+'\n",
    "    number_str = '\\d+.?\\d+'\n",
    "    for line in open(file,\"r\"):\n",
    "        if metric in line:\n",
    "            word = re.findall(target_str, line)[0]\n",
    "            mtc = re.findall(number_str, word)[0]\n",
    "            \n",
    "            mtcs.append(mtc)\n",
    "            i = i + 1\n",
    "    return i, mtcs \n",
    "\n",
    "def insert_10(left, right):\n",
    "    l = [left + 1]\n",
    "    for i in range(left, right):\n",
    "        if (i - left -1) % 10 == 0 and i != left + 1:\n",
    "            l.append(i)\n",
    "    l.append(right)\n",
    "    return l\n",
    "\n",
    "def merge_stack(lists):\n",
    "    for i in range(len(lists)):\n",
    "        merged_l = []\n",
    "        l = lists[i]\n",
    "        for a in l:\n",
    "            for b in a:\n",
    "                merged_l.append(b)\n",
    "        lists[i] = merged_l\n",
    "    return lists\n",
    "\n",
    "def cut(x,y,upper_bound_acc):\n",
    "    x = np.array(x) / 3600 # convert second to hour\n",
    "    threshold = 0\n",
    "    delete_y = [t for t in y if t > upper_bound_acc]\n",
    "    if len(delete_y) > 0:\n",
    "        if isinstance(y, list):\n",
    "            threshold = y.index(delete_y[0])\n",
    "        else:\n",
    "            threshold = y.tolist().index(delete_y[0])\n",
    "    else:\n",
    "        threshold = len(y)\n",
    "    y = y[:threshold]\n",
    "    x = x[:threshold]\n",
    "    return x,y\n",
    "            \n",
    "def sum_duration(depth, width, idx, tmp, time, type = \"Dyna-A-Freeze\", dataset = \"20news\"):\n",
    "    if dataset == \"20news\":\n",
    "        batch_num = 29\n",
    "    if dataset == \"agnews\":\n",
    "        batch_num = 30\n",
    "    if dataset == \"semeval\":\n",
    "        batch_num = 20\n",
    "    if dataset == \"onto\":\n",
    "        batch_num = 20\n",
    "\n",
    "    if dataset == \"20news\" or dataset == \"onto\":\n",
    "        latency_tx2_baseline = np.array([0.5325, 0.612, 0.696, 0.791, 0.883, 0.9713, 1.064, 1.156, 1.2465, 1.33, 1.419, 1.51, 1.7]) \n",
    "        latency_tx2_adapter = np.array([0.57, 0.57, 0.63, 0.66, 0.71, 0.75, 0.79, 0.84, 0.89, 0.94, 0.99, 1.03, 1.08])\n",
    "        latency_tx2_cached = np.array([0.02, 0.09, 0.18, 0.27, 0.36, 0.45, 0.54, 0.63, 0.72, 0.81, 0.90, 0.99, 1.08]) # msl = 256\n",
    "    else:\n",
    "        latency_tx2_baseline = np.array([0.5325, 0.612, 0.696, 0.791, 0.883, 0.9713, 1.064, 1.156, 1.2465, 1.33, 1.419, 1.51, 1.7]) / 4\n",
    "        latency_tx2_adapter = np.array([0.57, 0.57, 0.63, 0.66, 0.71, 0.75, 0.79, 0.84, 0.89, 0.94, 0.99, 1.03, 1.08]) / 4\n",
    "        latency_tx2_cached = np.array([0.02, 0.09, 0.18, 0.27, 0.36, 0.45, 0.54, 0.63, 0.72, 0.81, 0.90, 0.99, 1.08]) / 4# msl = 64\n",
    "    comm_bert = np.array([0.6, 7.7, 14.8, 21.9, 29.0, 36.0, 43.1, 50.2, 57.3, 64.4, 71.5, 78.6, 109.5]) * 32 / 8 # 这里面没有仅仅freeze embedding的数据\n",
    "    adapter_para = 0.0125 * width / 8\n",
    "    comm_adapter =np.array([0.02 + i * adapter_para for i in range(0,13)]) * 4\n",
    "    \n",
    "    if type == \"BERT\":\n",
    "        latency = latency_tx2_baseline\n",
    "        comm = comm_bert * 2\n",
    "    elif type == \"Adapter\":\n",
    "        latency = latency_tx2_adapter\n",
    "        comm = comm_adapter * 2\n",
    "    elif type == \"Cache\":\n",
    "        latency = latency_tx2_cached\n",
    "        comm = comm_adapter * 2\n",
    "\n",
    "    comm_tmp = comm[depth]\n",
    "    duration = 0\n",
    "    for i in range(0, idx - tmp):\n",
    "        comp_tmp = latency[depth] * batch_num\n",
    "        duration = duration + comp_tmp + comm_tmp\n",
    "        # print(comp_tmp,comm_tmp)\n",
    "    if len(time) > 0:\n",
    "        time.append(duration + time[-1])\n",
    "    else:\n",
    "        time.append(duration)\n",
    "    return time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_acc = 0.99\n",
    "runtime = {\n",
    "    \"20news\": [],\n",
    "    \"agnews\": [],\n",
    "    \"semeval\": [],\n",
    "    \"onto\": []\n",
    "    # TODO: 这里的onto应该是模拟的到达0.8准确率的时间,也不对，反正onto的数据有点问题\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT 43.95175\n",
      "Adapter 6.147444444444437\n",
      "2\n",
      "Adapter optimal 4.916249999999992\n",
      "Adapter optimal cached 1.4725000000000026\n"
     ]
    }
   ],
   "source": [
    "# 20news\n",
    "root_path = \"/Users/cdq/Desktop/opensource/FedFinetuning/\"\n",
    "\n",
    "Origin = os.path.join(root_path,\"data/Baseline/20news_uniform_lr=0.1_freeze=_quantize=False_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Quant = os.path.join(root_path,\"data/Baseline/20news_uniform_lr=0.1_freeze=_quantize=True_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Q_Freeze = os.path.join(root_path,\"data/Baseline/20news_uniform_lr=0.1_freeze=e,0,1,2,3,4,5,6,7,8,9_quantize=True_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Freeze = os.path.join(root_path,\"data/Baseline/20news_uniform_lr=0.1_freeze=e,0,1,2,3,4,5,6,7,8,9_quantize=False_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*10).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_origin_drm = load_baseline(12, Origin)\n",
    "baseline_quant = load_baseline(12, Quant)\n",
    "baseline_q_freeze_drm = load_baseline(2, Q_Freeze)\n",
    "baseline_freeze_drm = load_baseline(2, Freeze)\n",
    "\n",
    "max_acc = 0.8\n",
    "max_acc = max_acc * target_acc\n",
    "\n",
    "time = []\n",
    "tmp = -1 # 记录最后一个访问的idx\n",
    "data = baseline_origin_drm\n",
    "y = [float(i) for i in baseline_origin_drm[2]]\n",
    "for idx in data[1]:\n",
    "    id = data[1].index(idx)\n",
    "    d = data[0][id]\n",
    "    w = 0\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"BERT\", \"20news\")\n",
    "    tmp = idx\n",
    "\n",
    "time, y = cut(time, y, max_acc)\n",
    "print(\"BERT\",time[-1])\n",
    "runtime[\"20news\"].append(time[-1])\n",
    "\n",
    "\n",
    "data_path = \"./Baseline/20news.csv\"\n",
    "raw_data = pd.read_csv(data_path,index_col=0)\n",
    "column_name = raw_data.columns.values\n",
    "\n",
    "col = \"Depth-3-Width-32 - Evaluation Accuracy\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = int(col.split(\"-\")[3])\n",
    "d = int(col.split(\"-\")[1])\n",
    "d = 12\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Adapter\", \"20news\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter\",time[-1])\n",
    "runtime[\"20news\"].append(time[-1])\n",
    "\n",
    "col = \"Depth-2-Width-8 - Evaluation Accuracy\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = int(col.split(\"-\")[3])\n",
    "d = int(col.split(\"-\")[1])\n",
    "print(d)\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Adapter\", \"20news\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter optimal\",time[-1])\n",
    "runtime[\"20news\"].append(time[-1])\n",
    "\n",
    "col = \"Depth-2-Width-8 - Evaluation Accuracy\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = int(col.split(\"-\")[3])\n",
    "d = int(col.split(\"-\")[1])\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Cache\", \"20news\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter optimal cached\",time[-1])\n",
    "runtime[\"20news\"].append(time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT 73.075\n",
      "Adapter 7.255555555555534\n",
      "Adapter optimal 3.172222222222234\n",
      "Adapter optimal cached 1.547222222222225\n"
     ]
    }
   ],
   "source": [
    "# agnews\n",
    "root_path = \"/Users/cdq/Desktop/opensource/FedFinetuning/\"\n",
    "\n",
    "Origin = os.path.join(root_path,\"data/Baseline/agnews_niid_label_clients=1000_alpha=10.0_lr=0.1_freeze=_quantize=False_adapter=False_length=64.txt\")\n",
    "Quant = os.path.join(root_path,\"data/Baseline/agnews_niid_label_clients=1000_alpha=10.0_lr=0.1_freeze=_quantize=True_adapter=False_length=64.txt\")\n",
    "Q_Freeze = os.path.join(root_path,\"data/Baseline/agnews_niid_label_clients=1000_alpha=10.0_lr=0.1_freeze=e,0,1,2,3,4,5,6,7,8,9_quantize=True_adapter=False_MSL=64_workers15_rounds10.txt\")\n",
    "Freeze = os.path.join(root_path,\"data/Baseline/agnews_niid_label_clients=1000_alpha=10.0_lr=0.1_freeze=e,0,1,2,3,4,5,6,7,8,9_quantize=False_adapter=False_MSL=64_workers15_rounds10.txt\")\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*5).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_origin_drm = load_baseline(12, Origin)\n",
    "baseline_quant = load_baseline(12, Quant)\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*10).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_q_freeze_drm = load_baseline(2, Q_Freeze)\n",
    "baseline_freeze_drm = load_baseline(2, Freeze)\n",
    "# print(baseline_quant)\n",
    "\n",
    "max_acc = 0.9\n",
    "max_acc = max_acc * target_acc\n",
    "\n",
    "\n",
    "time = []\n",
    "tmp = -1 # 记录最后一个访问的idx\n",
    "data = baseline_origin_drm\n",
    "y = [float(i) for i in baseline_origin_drm[2]]\n",
    "for idx in data[1]:\n",
    "    id = data[1].index(idx)\n",
    "    d = data[0][id]\n",
    "    w = 0\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"BERT\", \"agnews\")\n",
    "    tmp = idx\n",
    "\n",
    "time, y = cut(time, y, max_acc)\n",
    "print(\"BERT\",time[-1])\n",
    "runtime[\"agnews\"].append(time[-1])\n",
    "\n",
    "\n",
    "data_path = \"./Baseline/agnews-adapter.csv\"\n",
    "raw_data = pd.read_csv(data_path,index_col=0)\n",
    "column_name = raw_data.columns.values\n",
    "\n",
    "col = \"depth-2\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = 32\n",
    "d = 12\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Adapter\", \"agnews\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter\",time[-1])\n",
    "runtime[\"agnews\"].append(time[-1])\n",
    "\n",
    "col = \"depth-2\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = 16\n",
    "d = 3\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Adapter\", \"agnews\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter optimal\",time[-1])\n",
    "runtime[\"agnews\"].append(time[-1])\n",
    "\n",
    "col = \"depth-2\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = 16\n",
    "d = 3\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Cache\", \"agnews\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter optimal cached\",time[-1])\n",
    "runtime[\"agnews\"].append(time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT 124.32138888888889\n",
      "Adapter 2.676333333333339\n",
      "Adapter optimal 1.578416666666668\n",
      "Adapter optimal cached 1.4621666666666675\n"
     ]
    }
   ],
   "source": [
    "# semeval\n",
    "root_path = \"/Users/cdq/Desktop/opensource/FedFinetuning/\"\n",
    "\n",
    "Origin = os.path.join(root_path,\"data/Baseline/semeval_2010_task8_niid_label_clients=100_alpha=100_lr=0.1_freeze=_quantize=False_adapter=False_length=64.txt\")\n",
    "Quant = os.path.join(root_path,\"data/Baseline/semeval_2010_task8_niid_label_clients=100_alpha=100_lr=0.1_freeze=_quantize=True_adapter=False_length=64.txt\")\n",
    "Q_Freeze = os.path.join(root_path,\"data/Baseline/semeval_2010_task8_niid_label_clients=100_alpha=100_lr=0.1_freeze=e,0,1,2,3,4,5_quantize=True_adapter=False_MSL=64_workers15_rounds10.txt\")\n",
    "Freeze = os.path.join(root_path,\"data/Baseline/semeval_2010_task8_niid_label_clients=100_alpha=100_lr=0.1_freeze=e,0,1,2,3,4,5_quantize=False_adapter=False_MSL=64_workers15_rounds10.txt\")\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*5).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_origin_drm = load_baseline(12, Origin)\n",
    "baseline_quant = load_baseline(12, Quant)\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*10).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_q_freeze_drm = load_baseline(6, Q_Freeze)\n",
    "baseline_freeze_drm = load_baseline(6, Freeze)\n",
    "\n",
    "max_acc = 0.8\n",
    "max_acc = max_acc * target_acc\n",
    "\n",
    "\n",
    "time = []\n",
    "tmp = -1 # 记录最后一个访问的idx\n",
    "data = baseline_origin_drm\n",
    "y = [float(i) for i in baseline_origin_drm[2]]\n",
    "for idx in data[1]:\n",
    "    id = data[1].index(idx)\n",
    "    d = data[0][id]\n",
    "    w = 0\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"BERT\", \"semeval\")\n",
    "    tmp = idx\n",
    "\n",
    "time, y = cut(time, y, max_acc)\n",
    "print(\"BERT\",time[-1])\n",
    "runtime[\"semeval\"].append(time[-1])\n",
    "\n",
    "\n",
    "data_path = \"./Baseline/semeval-adapter.csv\"\n",
    "raw_data = pd.read_csv(data_path,index_col=0)\n",
    "column_name = raw_data.columns.values\n",
    "\n",
    "col = \"depth-12\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = 32\n",
    "d = 12\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Adapter\", \"semeval\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter\",time[-1])\n",
    "runtime[\"semeval\"].append(time[-1])\n",
    "\n",
    "col = \"depth-12\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = 8\n",
    "d = 10\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Adapter\", \"semeval\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter optimal\",time[-1])\n",
    "runtime[\"semeval\"].append(time[-1])\n",
    "\n",
    "col = \"depth-12\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = 8\n",
    "d = 10\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Cache\", \"semeval\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter optimal cached\",time[-1])\n",
    "runtime[\"semeval\"].append(time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT 76.08611111111111\n",
      "Adapter 8.484444444444428\n",
      "Adapter optimal 8.484444444444428\n",
      "Adapter optimal cached 8.484444444444428\n"
     ]
    }
   ],
   "source": [
    "# onto\n",
    "root_path = \"/Users/cdq/Desktop/opensource/FedFinetuning/\"\n",
    "\n",
    "\n",
    "Origin = os.path.join(root_path,\"data/Baseline/onto_niid_label_clients=30_alpha=1.0_lr=0.1_freeze=_quantize=False_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Quant = os.path.join(root_path,\"data/Baseline/onto_niid_label_clients=30_alpha=1.0_lr=0.1_freeze=_quantize=True_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Q_Freeze = os.path.join(root_path,\"data/Baseline/onto_niid_label_clients=30_alpha=1.0_lr=0.1_freeze=e,0,1,2,3,4,5_quantize=False_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "Freeze = os.path.join(root_path,\"data/Baseline/onto_niid_label_clients=30_alpha=1.0_lr=0.1_freeze=e,0,1,2,3,4,5_quantize=True_adapter=False_MSL=256_workers15_rounds10.txt\")\n",
    "def load_baseline(depth, file):\n",
    "    baseline = []\n",
    "    for line in open(file,\"r\"):\n",
    "        baseline.append(float(line))\n",
    "    baseline_len = len(baseline)\n",
    "    baseline_drm = [[depth]*baseline_len, (np.array(range(0, baseline_len))*10).tolist(), baseline]\n",
    "    return baseline_drm\n",
    "baseline_origin_drm = load_baseline(12, Origin)\n",
    "baseline_quant = load_baseline(12, Quant)\n",
    "# baseline_q_freeze_drm = load_baseline(6, Q_Freeze)\n",
    "# 对应table2，此处应该至少是8\n",
    "baseline_q_freeze_drm = load_baseline(6, Q_Freeze)\n",
    "baseline_freeze_drm = load_baseline(6, Freeze)\n",
    "\n",
    "max_acc = 0.75\n",
    "max_acc = max_acc * target_acc\n",
    "\n",
    "\n",
    "time = []\n",
    "tmp = -1 # 记录最后一个访问的idx\n",
    "data = baseline_origin_drm\n",
    "y = [float(i) for i in baseline_origin_drm[2]]\n",
    "for idx in data[1]:\n",
    "    id = data[1].index(idx)\n",
    "    d = data[0][id]\n",
    "    w = 0\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"BERT\", \"onto\")\n",
    "    tmp = idx\n",
    "\n",
    "time, y = cut(time, y, max_acc)\n",
    "print(\"BERT\",time[-1])\n",
    "runtime[\"onto\"].append(time[-1])\n",
    "\n",
    "\n",
    "data_path = \"./Baseline/onto-adapter.csv\"\n",
    "raw_data = pd.read_csv(data_path,index_col=0)\n",
    "column_name = raw_data.columns.values\n",
    "\n",
    "col = \"depth-12-width-32\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = 32\n",
    "d = 12\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Adapter\", \"onto\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter\",time[-1])\n",
    "runtime[\"onto\"].append(time[-1])\n",
    "\n",
    "col = \"depth-12-width-32\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = 32\n",
    "d = 12\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Adapter\", \"onto\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter optimal\",time[-1])\n",
    "runtime[\"onto\"].append(time[-1])\n",
    "\n",
    "col = \"depth-12-width-32\"\n",
    "time = []\n",
    "multiple = 10\n",
    "w = 32\n",
    "d = 12\n",
    "data = raw_data.iloc[:,column_name.tolist().index(col)].dropna()\n",
    "round_idx = np.array(list(range(0,len(data)))) * multiple\n",
    "tmp = -1 * multiple # 记录最后一个访问的idx\n",
    "for idx in round_idx:\n",
    "    time = sum_duration(d, w, idx, tmp, time, \"Cache\", \"onto\")\n",
    "    tmp = idx\n",
    "time, data = cut(time, data, max_acc)\n",
    "print(\"Adapter optimal cached\",time[-1])\n",
    "runtime[\"onto\"].append(time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20news': [43.95175,\n",
       "  6.147444444444437,\n",
       "  4.916249999999992,\n",
       "  1.4725000000000026],\n",
       " 'agnews': [73.075, 7.255555555555534, 3.172222222222234, 1.547222222222225],\n",
       " 'semeval': [124.32138888888889,\n",
       "  2.676333333333339,\n",
       "  1.578416666666668,\n",
       "  1.4621666666666675],\n",
       " 'onto': [76.08611111111111,\n",
       "  8.484444444444428,\n",
       "  8.484444444444428,\n",
       "  8.484444444444428]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b70465f8729e5d3096f68a9386b4f93afdddeed84afbab797b784e9c714821a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('fednlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
